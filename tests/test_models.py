#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•Aether-Liteç§»æ¤åçš„æ¨¡å—
"""

import torch
import sys
import os

# ç¡®ä¿èƒ½å¯¼å…¥modelsåŒ…
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from models import (
    LiteSpeechJSCC,
    AetherBaseSpeechJSCC,
    create_lite_speech_jscc,
    create_aether_base,
    HashBottleneck,
    FARGANDecoder
)

def test_lite_speech_jscc():
    """æµ‹è¯•LiteSpeechJSCCæ¨¡å‹"""
    print("=" * 50)
    print("Testing LiteSpeechJSCC")
    print("=" * 50)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = create_lite_speech_jscc(device=device)

    # æ¨¡å‹ä¿¡æ¯
    info = model.get_model_info()
    print(f"Model: {info['model_name']}")
    print(f"Total Parameters: {info['total_parameters']:,}")
    print(f"Parameter Size: {info['parameter_size_mb']:.2f} MB")
    print(f"Bitrate: {info['bitrate_kbps']:.1f} kbps")

    # æµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 100
    x_feat = torch.randn(batch_size, seq_len, 36).to(device)
    csi = torch.randn(batch_size, 3).to(device)

    # æµ‹è¯•è¿ç»­JSCC
    feat_hat, z_hat, z = model.forward_continuous(x_feat, csi, snr_db=10.0)
    print(f"Continuous JSCC - feat_hat: {feat_hat.shape}")

    # æµ‹è¯•Hash JSCC
    feat_hat_h, z_q, z_hat_h, hash_out = model.forward_hash(x_feat, csi, snr_db=10.0)
    print(f"Hash JSCC - feat_hat: {feat_hat_h.shape}")

    print("âœ… LiteSpeechJSCC test passed!\n")


def test_aether_base():
    """æµ‹è¯•AetherBaseæ¨¡å‹"""
    print("=" * 50)
    print("Testing AetherBaseSpeechJSCC")
    print("=" * 50)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_base = create_aether_base(device=device)

    # æ¨¡å‹ä¿¡æ¯
    info = model_base.get_model_info()
    print(f"Model: {info['model_name']}")
    print(f"Role: {info['role']}")
    print(f"Total Parameters: {info['total_parameters']:,}")
    print(f"Parameter Size: {info['parameter_size_mb']:.2f} MB")

    # æµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 100
    x_feat = torch.randn(batch_size, seq_len, 36).to(device)
    csi = torch.randn(batch_size, 3).to(device)

    # æµ‹è¯•è’¸é¦ç›®æ ‡ç”Ÿæˆ
    targets = model_base.get_distillation_targets(x_feat, csi, snr_db=10.0)
    print(f"Distillation targets - z_base: {targets['z_base'].shape}")
    print(f"Distillation targets - audio_base: {targets['audio_base'].shape}")

    print("âœ… AetherBase test passed!\n")


def test_parameter_comparison():
    """å¯¹æ¯”å‚æ•°é‡"""
    print("=" * 50)
    print("Parameter Comparison")
    print("=" * 50)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # åˆ›å»ºæ¨¡å‹
    model_lite = create_lite_speech_jscc(device=device)
    model_base = create_aether_base(device=device)

    # è·å–ä¿¡æ¯
    info_lite = model_lite.get_model_info()
    info_base = model_base.get_model_info()

    print(f"Lite Parameters: {info_lite['total_parameters']:,}")
    print(f"Base Parameters: {info_base['total_parameters']:,}")
    print(f"Base/Lite Ratio: {info_base['total_parameters']/info_lite['total_parameters']:.1f}x")

    # éªŒè¯å‚æ•°é‡åœ¨é¢„æœŸèŒƒå›´å†…
    lite_params_mb = info_lite['parameter_size_mb']
    base_params_mb = info_base['parameter_size_mb']

    print(f"Lite Size: {lite_params_mb:.2f} MB (Target: 2-5 MB)")
    print(f"Base Size: {base_params_mb:.2f} MB (Target: 5-10 MB)")

    # éªŒè¯
    if 2 <= lite_params_mb <= 5:
        print("âœ… Liteå‚æ•°é‡åœ¨ç›®æ ‡èŒƒå›´å†…")
    else:
        print("âŒ Liteå‚æ•°é‡è¶…å‡ºç›®æ ‡èŒƒå›´")

    if 5 <= base_params_mb <= 10:
        print("âœ… Baseå‚æ•°é‡åœ¨ç›®æ ‡èŒƒå›´å†…")
    else:
        print("âŒ Baseå‚æ•°é‡è¶…å‡ºç›®æ ‡èŒƒå›´")

    print()


def test_core_components():
    """æµ‹è¯•æ ¸å¿ƒç»„ä»¶"""
    print("=" * 50)
    print("Testing Core Components")
    print("=" * 50)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # æµ‹è¯•HashBottleneck
    hash_bottleneck = HashBottleneck(
        input_dim=16,
        hash_bits=16,
        hash_method='bihalf'
    ).to(device)

    x = torch.randn(2, 100, 16).to(device)
    hash_result = hash_bottleneck(x, {'ber': 0.1})
    print(f"âœ… HashBottleneck - input: {x.shape}, output: {hash_result['reconstructed'].shape}")

    # æµ‹è¯•FARGANDecoder
    fargan_decoder = FARGANDecoder().to(device)
    feat = torch.randn(2, 100, 36).to(device)
    period, audio = fargan_decoder(feat)
    print(f"âœ… FARGANDecoder - feat: {feat.shape}, audio: {audio.shape}")

    print()


if __name__ == "__main__":
    print("ğŸš€ Testing Aether-Lite Migrated Modules")
    print("=" * 60)

    try:
        test_core_components()
        test_lite_speech_jscc()
        test_aether_base()
        test_parameter_comparison()

        print("ğŸ‰ All tests passed successfully!")
        print("âœ… æ‰€æœ‰æ ¸å¿ƒç»„ä»¶å·²æˆåŠŸç§»æ¤åˆ°Aether-liteç›®å½•")

    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()